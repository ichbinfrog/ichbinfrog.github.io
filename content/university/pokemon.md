---
title: "üá´üá∑ Pokemon victory prediction"
date: 2020-06-30T11:55:00+00:00
draft: false
toc: true
images:
tags:
  - ml
  - pokemon
  - svm
  - knn
  - decision tree
  - random forest
  - adaboost
---

> Ce travail a √©t√© fait avec Alix CANDUSSO et Chen GONG dans le cadre de l'UV SY09.

> Issu d'une franchise de jeu vid√©o japonaise, un pok√©mon est une cr√©ature qui, une fois captur√©e par un dresseur, peut-√™tre envoy√© pour affronter les pok√©mon d'un autre dresseur. R√©gi par un ensemble de r√®gles bien d√©finies, la complexit√© des combats qui en d√©rive et les mod√®les qui les pr√©disent constituent l'int√©r√™t de cette √©tude. 

## Analyse exploratoire
Cette collection, provenant de [Kaggle](https://www.kaggle.com/terminus7/pokemon-challenge"), est constitu√©e de trois jeu de donn√©es diff√©rents;

### Caract√©ristiques d'un pok√©mon 
Ce jeu de donn√©es pr√©sente les caract√©ristiques de 800 pok√©mon extraites directement du code objet du jeu. Chaque pok√©mon, identifi√© de mani√®re unique par un nom ou un entier, se caract√©rise par un bool√©en qui indique s'il est **l√©gendaire** ainsi que par sa **g√©n√©ration** ("version" √† partir de laquelle le pok√©mon a √©t√© ajout√©). Un pok√©mon est aussi caract√©ris√© par ses statistiques; 
- **speed**: d√©termine s'il prend l'initiative lors d'un combat
- **hp**: nombre de point de dommages qu'il peut subir avant d'√™tre √©limin√©
- **attack**: puissance de ses attaques physiques
- **defense**: r√©sistance aux attaques physiques
- **sp. attack**: puissance des attaques "magiques" (le pokemon ne touche physiquement pas son adversaire mais inflige tout de m√™me des d√©g√¢ts)
- **sp. defense**: r√©sistance aux attaques sp√©ciales

Normalement, les statistiques d'un pok√©mon sont bas√©es sur des statistiques de base augmentent lorsque le pok√©mon monte en niveau, mais cette dimension n'est pas consid√©r√©e dans ce jeu de donn√©es. De plus, chaque pok√©mon appartient √† un ou deux **types** (e.g. Feu, Eau, Acier, √âlectricit√©, Vol...) qui indique quelles capacit√©s peuvent √™tre apprises et ses forces/faiblesses par rapport √† des pok√©mon d'autres types (e.g. les pokemon de type Feu sont plus vuln√©rables aux attaques de type Eau, mais plus r√©sistants aux attaques de type Plante).

### Combats 

Ce tableau pr√©sente les codes des bellig√©rants de 50001 duels et le vainqueur. Ces triplets synth√©tiques sont g√©n√©r√©s par un algorithme qui simplifie certains aspects du jeu notamment les capacit√©s. En r√©alit√©, un combat se d√©roule selon les r√®gles suivantes:
- Le pok√©mon pr√©sent dans la premi√®re colonne dispose de l'initiative pour le premier tour.
- √Ä chaque tour, chaque pok√©mon choisit et utilise une de ses quatre capacit√©s (une attaque physique ou sp√©ciale, une attaque de modification de statistiques, etc) jusqu'√† ce que les points de vie de l'un des deux tombe √† 0 et la victoire est alors accord√©e √† l'autre. 


Afin d'all√©ger la notation, notons dor√©navant $\Omega$ (l'ensemble des pok√©mon) et donc $\Omega^2$ (l'ensemble des statistiques de deux pok√©mon qui s'affrontent en duel). 

En interpolant √† partir des donn√©es sur les combats, on peut √©mettre l'hypoth√®se que le r√©sultat d'un combat entre deux pok√©mons est **d√©terministe** car:
- Il n'y a pas de combats o√π un pok√©mon affronte l'exact m√™me pok√©mon. Si ce cas de figure existe, les deux bellig√©rants auraient exactement les m√™mes statistiques de combats et le r√©sultat devrait donc √™tre soit d√©cid√© de mani√®re al√©atoire soit une *√©galit√©*. 
- Il n'y a pas deux combats entre $p_1$ et $p_2$ o√π dans l'un $p_1$ attaque en premier et dans l'autre il attaque en deuxi√®me.
- Chaque combat a un gagnant unique.

Il est donc possible de construire un classifieur binaire pour pr√©dire le r√©sultat d'un combat o√π $True$ correspond √† la victoire du premier pok√©mon qui attaque et $False$ sinon. N√©anmoins, seulement $14.409\%$ des combinaisons de paires possibles de pok√©mon sont repr√©sent√©es donc notre mod√®le sera entra√Æn√© sur une partie relativement petite de l'ensemble $\Omega^2$. Un √©chantillon de test accompagne aussi la table des combats. Tout de m√™me, celui-ci est inutile pour v√©rifier la validit√© du mod√®le car il ne pr√©sente pas le code du vainqueur. 

### Probl√©matique

Le but ce cette √©tude est donc d'appliquer un large √©ventail d'algorithmes d'apprentissage supervis√©s et non supervis√©s afin de construire un mod√®le, qui, prend en entr√©e deux pok√©mon et pr√©dit le gagnant.

---
## Enrichissement du jeu de donn√©es

### Introduction d'une hi√©rarchie

Un pok√©mon dispose parfois d'une cha√Æne d'√©volution (e.g. Salam√®che $\rightarrow$ Reptincel $\rightarrow$ Dracaufeu), les pok√©mon en fin de cha√Æne √©tant en g√©n√©ral plus puissants que ceux en d√©but. Afin de tester si cette cat√©gorisation hi√©rarchique contribue √† la am√©liorer la classification, nous avons introduit le stage d'√©volution d'un pokemon (0 √©tant l'√©tat en d√©but de cha√Æne d'√©volution qui incr√©mente de 1 jusqu'√† ce qu'on atteint un pok√©mon en fin de cha√Æne) gr√¢ce √† [PokeAPI](https://pokeapi.co/).

     
**Ajout d'une m√©trique**

Afin de combiner le jeu de donn√©es des pok√©mon et des combats, il est possible de comprimer le tableau de combats en une seule m√©trique, le taux de victoire avec la formule:

$$win\\_rate(p_i) = \frac{nombre\\_de\\_victoires(p_i)}{nombre\\_de\\_combats(p_i)}$$

{{< caption title="Matrice des corr√©lations des caract√©ristiques des pok√©mon" >}}
{{< image src="/img/pokemon_heatmap.png"  position="center" >}}

La matrice de corr√©lation issue du jeu de donn√©e enrichi d√©montre une corr√©lation forte entre la vitesse d'un pok√©mon et son taux de victoire ainsi que le niveau d'√©volution et la g√©n√©ration. La deuxi√®me relation s'explique par l'introduction des cha√Ænes d'√©volutions plus longues au fur et √† mesure de la parution de nouveaux jeux Pok√©mon (e.g. √©volutions m√©ga, X ou Y). 

Il est tout de m√™me surprenant que les attributs de d√©fenses (hp, defense, sp. defense) affectent tr√®s peu le taux de victoire du pok√©mon. Au contraire, les attributs offensifs (speed, attack, sp. attack) sont plus fortement corr√©l√©s √† la probabilit√© de gagner un duel.

{{< image src="/img/pokemon_reg.png"  position="center" >}}
{{< caption title="Regr√©ssion des attributs les plus fortement corr√©l√©s au taux de victoire" >}}


De m√™me, le jeu de donn√©es des combats peut √™tre enrichi en ajoutant les caract√©ristiques de chaque participants. Tout de m√™me, le tableau individu-variable de taille importante ($50001$ lignes et $21$ colonnes) qui en r√©sulte ralentit l'entra√Ænement des algorithmes et augmente la quantit√© de ressource consomm√©e. Il sera donc n√©cessaire de r√©duire ses dimensions via des algorithmes lin√©aires (PCA) lin√©aire ou en agr√©geant les attributs en des m√©triques plus cons√©quentes. 

Au lieu de consid√©rer les attributs attaque/attaque sp√©ciale et d√©fense/d√©fense sp√©ciale, il est aussi possible d'additionner les deux statistiques pour en former une statistique *attaque* et *d√©fense* plus g√©n√©rale (ce jeu de donn√©e s'appellera d√©sormais *reduced\_diff*).

**Impact des types**

Afin d'√©tudier l'impact des m√©canismes de faiblesse par rapport aux types des deux combattants sur l'issue du duel, deux attributs ont √©t√© ajout√©s, le multiplicateur de puissance d'attaque de chacun des pok√©mon. Ces derni√®res r√©duisent quatre valeurs qualitatives (cat√©gorie) en deux valeurs quantitatives gr√¢ce √† la formule:

$$\tau_{type_1(p_1),type_1(p_2)} \times \tau_{type_1(p_1),type_2(p_2)}$$

$$\tau_{type_2(p_1),type_1(p_2)} \times \tau_{type_2(p_1),type_2(p_2))}$$

Avec $\tau$ la matrice des multiplicateurs de la puissance d'attaque de la VII√®me g√©n√©ration, avec $\tau_{t_1,t_2} \in \mathbb{R}^+$ le multiplicateur d'attaquant de type $t_1$ par rapport √† un d√©fendant de type $t_2$. Afin d'obtenir le multiplicateur dans le sens inverse, il suffit de prendre $mult(p_2, p_1)$. 

|                          | victoire du 1er pok√©mon | victoire du 2nd pok√©mon |
|:------------------------:|:-----------------------:|:-----------------------:|
| mult(p1,p2)> mult(p2,p1) |         0.51346         |         0.48654         |
|  mult(p1,p2)=mult(p2,p1) |         0.481212        |         0.518788        |
| mult(p1,p2)< mult(p2,p1) |         0.415805        |         0.584195        |
|           total          |         0.47202         |         0.52798         |


La matrice de contingence relative entre ses multiplicateurs et l'issue du combat, r√©v√®le une inclinaison positive vers la victoire du $2^{nd}$ pok√©mon ainsi qu'une absence de corr√©lation claire entre l'avantage que conf√®re le type et la victoire.


---
## R√©duction des dimensions

### Analyse en composantes principales

Pour le jeu de donn√©es des combats, la colonne *vainqueur* pose probl√®me puisqu'elle est logiquement fortement corr√©l√©e √† *first\_pokemon* et *second\_pokemon* et difficilement manipulable. La conversion de l'attribut *vainqueur* en un bool√©en qui repr√©sente si le vainqueur correspond bien au premier pok√©mon, donne un domaine $\Omega^2 \times \{True, False\}$ plus facile √† manipuler. 

D√®s lors, l'application d'une ACP s'av√®re utile √† cause du fl√©au de la dimension en permettant de projeter l'espace pr√©c√©dente dans un espace $\mathbb{R}^n$ avec $n$ le nombre d'axes factoriels. Les contributions relatives des axes d'une ACP avec l'ensemble du tableau r√©v√®lent un coude au niveau du deuxi√®me axe factoriel. N√©anmoins, m√™me si les premiers et deuxi√®mes axes expliquent $91.36\%$ de l'inertie totale, l'introduction d'un troisi√®me axe donne une structure nettement s√©par√©e entre les classes au lieu des classes confondues (axe1-axe3).

{{< image src="/img/pokemon_battles_pca.png"  position="center" >}}
{{< caption title="ACP des combats √† trois axes factoriels." >}}


### Matrice de distance interm√©diaire

Il est possible de r√©duire l'espace sans une ACP en soustrayant les statistiques des combattants. Certaines des diff√©rences obtenues corr√®lent fortement √† l'issue du duel. La combinaison de ces diff√©rences peut donc r√©v√©ler une fonction de distance $d:\Omega^2 \mapsto \mathbb{R}$ et une fonction de r√©gression $r: \mathbb{R} \mapsto \{True, False\}$ qui donne en combinaison la classification voulue : $clf = r \circ d$. 

Tout de m√™me, la table des combats contient des variables qui ne permet pas √† l'√©valuation. Les variables qualitatives comme le type des pok√©mon sont transform√©es par la formule des types. Les attributs bool√©ennes peuvent √™tre convertis en $0(False), 1(True)$ puis une soustrait. N√©anmoins, puisque cette conversion nu√Æt √† l'interpr√©tabilit√© du mod√®le, les variables bool√©ennes sont alors √©limin√©es. 

{{< image src="/img/pokemon_battles_heatmap.png"  position="center" >}}


Pour les autres statistiques de combats et les taux de victoires, une diff√©rence absolue est utilis√©e afin de respecter la sym√©trie de la distance. Il est possible d'utiliser la diff√©rence exacte de la diff√©rence des taux de victoires mais celle-ci n√©cessite que l'ensemble des anciens adversaires soient relativement cons√©quentes. Or, la matrice des combats est creuse ($14\%$ de remplissage).

$$\frac{|V(p_1) \cap Adv(p_1,p_2)| - |V(p_2)\cap Adv(p_1,p_2)|}{|Adv(p_1,p_2)|}$$

$$V(p_1) = vaincus\, par\, p_1$$

$$Adv(p_1) = adversaires\, de\, p_1$$

$$Adv(p_1,p_2) = Adv(p_1) \cap Adv(p_2)$$

De plus, il est possible de r√©duire d'autant plus la dimension en effectuant une ACP sur ces diff√©rences. La m√©thode du coude r√©v√®le que 6 axes factoriels expliquent la majorit√© de la variance expliqu√©e. 

---
## K Plus Proches Voisins (KNN)

### Principe

L'algorithme des KNN est une m√©thode de classification supervis√©e qui ne n√©cessite pas d'apprentissage. Lorsque l'on souhaite classer une nouvelle donn√©e, on rel√®ve les K plus proches voisins (en termes d'attributs) parmi le jeu de donn√©es existant et on classe cette nouvelle donn√©e dans la classe pr√©dominante parmi les K plus proches voisins qui l'entourent.

### Application

En faisant varier le nombre de dimensions de la PCA, on observe que la performance de l'algorithme sur le dataset des diff√©rences est optimale √† 6 axes factoriels. De plus, la r√©duction de la dimension semble diminuer le nombre de voisins √† partir duquel les KNNs convergent vers la qualit√© de pr√©diction optimale.  

{{< image src="/img/pokemon_knn_battles_difference_df.png"  position="center" >}}
{{< caption title="Validation crois√©e √† 5 coupes des KNN en fonction du nombre K de voisins et de la dimension de l'ACP" >}}


Au-del√† d'un certain seuil de voisins, la croissance en terme de qualit√© de pr√©diction est n√©gligeable et ne justifie pas le co√ªt algorithmique suppl√©mentaire. Pour notre jeu de donn√©es, ce seuil se trouve aux alentours de 20 voisins et donne un accuracy\_score de $91\%$. De m√™me, l'application sur *reduced\_diff* donne les m√™mes observations mais avec une pr√©cision l√©g√®rement am√©lior√©e. 

Par d√©faut, l'impl√©mentation KNN de sklearn utilise une distance euclidienne pour trouver les voisins les plus proches et chaque individu est pond√©r√© de mani√®re uniforme. Le choix de la distance d√©termine en pratique la forme du volume de dimension $N$ qui d√©limite les fronti√®res d'un point;

- *euclidien* ($\sqrt{\Sigma(x - y)^2}$) : sph√®re de $N$ dimensions.
- *manhattan* ($\Sigma(|x - y|)$) : cube de $N$ dimensions
- *chebyshev* ($max(|x - y|)$) : cube de $N$ dimensions o√π la longueur correspond √† la distance maximale d'un attribut entre deux individus donn√©s.

La distance de *manhattan* aurait donc tendance de consid√©rer plus d'individus comme voisins que par rapport aux autres. En appliquant sur le jeu de donn√©es, on observe que l'utilisation de cette manhattan donne le meilleur estimateur parmi les autres distances. Une piste d'am√©lioration serait alors d'√©tudier l'effet des distances qui engendrent des volumes plus important (par exemple les distances de *minkowski* avec $p \in ]0,1[$).

{{< image src="/img/pokemon_knn_dist.png"  position="center" >}}
{{< caption title="Qualit√© du mod√®le KNN selon la distance et la pond√©ration des individus apr√®s validation crois√©e √† 5 coupes" >}}


De m√™me, la qualit√© du mod√®le issu de la distance de manhattan sugg√®re qu'il n'est pas sur-apprenti (l'inclusion de plus de points l'am√©liore). On peut donc renforcer l'effet de la distance dans l'algorithme en donnant chaque individu un poids qui correspond √† l'inverse de sa distance √† l'√©l√©ment √† classifier (option *distance* sur sklearn). Cette modification am√©liore un tout petit peu la qualit√© et confirme l'hypoth√®se pr√©c√©dente. 

---
## Support Vector Machine (SVM)

### Principe

Les machines √† vecteurs de support (Support Vector Machine) ont pour but de s√©parer les donn√©es en classes √† l‚Äôaide d‚Äôune fronti√®re aussi simple que possible, de telle fa√ßon que la distance entre les diff√©rents groupes de donn√©es et la fronti√®re qui les s√©pare soit maximale. Cette distance est aussi appel√©e **marge** et les donn√©es les plus proches de la fronti√®re sont appel√©es les **vecteurs de support**.


{{< image src="/img/pokemon_svm.png"  position="center" >}}
{{< caption title="Illustration d'un SVM avec la fronti√®re (droite noire), les vecteurs de support (points entour√©s) et les marge (droites bleue et rouge)" >}}


Pour un probl√®me de classification binaire, la fronti√®re de d√©cision est un hyperplan d√©fini par;
$$h(x)=w^{T}x+b = 0$$

$x$ les donn√©es d'entr√©e de dimension $N$, $w$ le vecteur des poids et $b$ la distance entre l'hyperplan et l'origine. Trouver l'hyperplan de marge maximale revient donc √†:

$$\frac  {1}{2}||w||^{2}, \quad \quad l_{k}(w^{T}x_{k}+w_{0})\geq 1$$

avec ${\displaystyle l_{k}}$ le label du vecteur $x_k$, ${\displaystyle l_{k}} \subset {\displaystyle \{-1,1\}}$.  Ceci peut se r√©soudre par la m√©thode classique des multiplicateurs de Lagrange, avec le lagrangien:

$$L(w,b,\alpha)=\frac {1}{2}||w||^{2}-\sum_{k=1}^{p}\alpha_{k}(l_{k}(w^{T}x_{k}+b)-1)$$

Le lagrangien doit √™tre minimis√© par rapport √† w et b, et maximis√© par rapport √† $\alpha$. Apr√®s avoir r√©solu $\alpha$, on trouve w et b pour obtenir le mod√®le:

$$h(x)=\sum_{k=1}^{p}\alpha_{k}^{*}l_{k}(x\cdot x_{k})+b$$


Pour les probl√®mes s√©parables non lin√©aires dans l'espace d'origine, l'√©chantillon peut √™tre mapp√© de l'espace d'origine vers un espace d'entit√©s de dimension sup√©rieure, de sorte que l'√©chantillon est s√©parable lin√©airement dans cet espace d'entit√©s gr√¢ce √† une fonction de noyau (**kernel**).


### Application

La cl√© de l'application d'une SVM r√©side dans la s√©lection des fonctions du noyau. Les fonctions de noyau doivent correspondre √† un produit scalaire et les plus couramment utilis√©es comprennent: 
\begin{itemize}
- **noyau lin√©aire** : sans changement d'espace, on se ram√®ne √† une classification lin√©aire. 
    
- **noyau polynomial** : 
    $K(u,v) = (coef0 + \langle u, v\rangle)^d$ avec $d$ le degr√© du polyn√¥me; un degr√© de $1$ revient √† faire un noyau lin√©aire et √† des degr√©s trop grand, le mod√®le risque de sur-apprendre.
    
- **fonction de base radiale** : 
    $K(u,v) = exp(-\gamma \times\Vert u, v\Vert)$. Cette fonction donne en g√©n√©rale des bons r√©sultats pour des s√©parations non lin√©aires. 

- **noyau sigmo√Øde**:
    $K(u,v) = tanh(\gamma \times\Vert u, v\Vert + coef0)$

La Figure suivante permet de visualiser la diff√©rence des marges et de la fronti√®re entre les noyaux. Tout de m√™me, il n'est pas possible de visualiser les donn√©es √† dimension $> 2$ et donc d'estimer quel kernel est le mieux adapt√©. 

{{< image src="/img/pokemon_svm_kernel.png"  position="center" >}}
{{< caption title="Comparaison de la fronti√®re des diff√©rentes kernel sur une PCA √† deux dimensions des diff√©rences des pok√©mons" >}}

En testant tout les kernels de base dans la librairie de sklearn, l'utilisation d'un kernel RBF donne en moyenne un meilleur estimateur ainsi que le temps d'entra√Ænement le plus rapide pour notre jeu de donn√©es.

|  kernel | accuracy score moyenne (cv 5) | temps d‚Äôentra√Ænement moyen (en s) |
|:-------:|:-----------------------------:|:---------------------------------:|
|  linear |            0.899007           |                3981               |
|   poly  |            0.864955           |               20.998              |
| sigmoid |             0.7146            |               27.892              |
|   rbf   |             0.9273            |               11.822              |


Le kernel RBF peut √™tre r√©gularis√© gr√¢ce √† deux param√®tres; $C$ et $\gamma$. O√π $C$ est le coefficient de p√©nalit√©, qui correspond √† la tol√©rance aux erreurs; un $C$ grand pousse le mod√®le √† apprendre parfaitement tandis qu'un $C$ petit cherche √† lisser la fronti√®re de d√©cision. Le gamma lui, d√©termine l'importance de chaque individus d'entra√Ænement; plus le $\gamma$ est petit, plus les vecteurs de support sont nombreux, ce qui r√©duit la vitesse d'entra√Ænement et de pr√©diction. 

En faisant une recherche al√©atoire sur les deux espaces, on observe qu'un coefficient de p√©nalit√© faible et un gamma faible am√©liore le r√©sultat.


---
## Arbre de d√©cision

### Principe

Ce mod√®le cherche √† construire une partition de l'espace $\Omega^2$ dans laquelle l'issue des combats dans chaque sous-ensemble est homog√®ne gr√¢ce √† un arbre binaire. 

A partir de la racine qui repr√©sente l'ensemble de d√©part, 0 √† 2 noeuds sont ajout√©s. Chaque noeud repr√©sente une *division*, c'est-√†-dire une condition sur un attribut ou une combinaison lin√©aire d'attributs coupant l'ensemble en deux sous-ensemble. Cette proc√©dure est r√©p√©t√©e pour chaque sous-ensemble r√©cursivement jusqu'√† l'obtention des partitions homog√®nes au sens de la variable √† pr√©dire. Afin d'avoir une s√©paration optimale √† chaque √©tape, l'algorithme cherche la division qui optimise le crit√®re d'*impuret√©* par une recherche √† *force brute* (it√©ration sur l'ensemble des seuils possibles). 

### R√©gularisation

La capacit√© de g√©n√©ralisation d'un arbre par rapport √† son ensemble d'apprentissage d√©pend fortement de sa profondeur. La d√©finition d'une **profondeur maximale** ou d'un nombre de noeuds maximal permettent de limiter la croissance manuellement √† condition qu'une division de l'espace soit trouv√©e lors des visualisations. Sinon, un \textbf{seuil minimal de d√©croissance d'un crit√®re} entre chaque d√©veloppement de l'arbre peut √™tre utilis√© pour limiter la croissance en complexit√© sans perdre la pr√©cision du mod√®le.

### Application


L'analyse de l'impact du param√®tre de croissance minimale d'impuret√© sur la qualit√© du mod√®le de pr√©diction de la victoire √† partir des diff√©rences montre qu'une croissance trop ralenti ($c_{min}>0.4$) entra√Æne un sous-apprentissage et une croissance non contr√¥l√©e un sur-apprentissage. 

De plus, l'optimum global obtenu √† $c_{min} = 0.15$ est commun entre les deux crit√®res de puret√© et produit deux arbres √©quivalents de profondeur 2. La bonne qualit√© de la pr√©diction ($94.5\%$ de bonne pr√©diction √† l'issu d'une validation crois√©e √† 5 coupes) s'accompagne aussi de l'interpr√©tabilit√© car le mod√®le revient √† deux conditions sur la diff√©rence de vitesse et d'attaque entre les deux pok√©mon.


{{< image src="/img/pokemon_tree_differences_entropy.png"  position="center" >}}
{{< caption title="Arbres de d√©cision de la diff√©rences des statistiques des combats et matrice de confusion sur l'√©chantillon de test de 12466 individus" >}}


La matrice de confusion r√©v√®le tout de m√™me qu'une grande partie des erreurs de classification commises s'explique par une sur-estimation de la capacit√© du premier pok√©mon. Ceci peut provenir d'un l√©ger biais pour la perte du premier pok√©mon que nous allons tenter de prendre en compte dans la partie For√™t Al√©atoire.

De plus, l'arbre de d√©cision produit un estimateur de variance √©lev√©e; les s√©parations sont optimis√©es localement et souvent sous-optimales, et donc chaque changement l√©ger dans les donn√©es produit des arbres compl√®tement diff√©rent.

## For√™t al√©atoire

### Principe

La for√™t al√©atoire permet de r√©gler le probl√®me de la variance des arbres de d√©cision en regroupant plusieurs arbres en un mod√®le plus complexe. 

L'algorithme consiste d'abord √† cr√©er $N$ r√©plications des donn√©es initiales $D$ par tirages avec remise, nomm√©s les √©chantillons de bootstrap $D^*_b$. On entra√Æne alors les arbres de d√©cisions $A_b$ avec les donn√©es d'entra√Ænements $D^*_b$ par un algorithme CART l√©g√®rement modifi√©; le d√©coupage choisi correspond √† la s√©paration qui optimise le crit√®re d'impuret√© sur un ensemble d'attributs tir√© al√©atoirement parmi les attributs. Finalement, le classement d'un individu se fait par vote majoritaire des arbres.

En moyennant les pr√©dictions d'un groupe d'arbre, on r√©duit la variance des arbres individuelles et en construisant des arbres sur des √©chantillons diff√©rentes et des attributs diff√©rents, on diminue le biais du mod√®le.  

### Application

La r√©gularisation d'une for√™t est similaire √† celle d'un arbre mise √† part le param√®tre du nombre d'arbres qui constituent la for√™t. De plus, afin de r√©duire l'effet du biais n√©gative des donn√©es, on peut attribuer d'un poids √† chaque classe pond√®re la proportion des classes dans le calcul des crit√®res d'impuret√©:

$$C_l(p) = p_l^{-}(1 - p_l^{-}) + p_l^{+}(1 - p_l^{+})$$

$$avec\ p_l^{-} = \frac{n_l^{-} \times w^{-}}{n_l}$$


Avec $C$ le crit√®re d'impuret√©, $p^{+}_l$ les proportions √† un noeud $l$ des diff√©rentes classes pour les individus de l'arbre inf√©rieur au seuil et $\omega_{+}$ le poids associ√© √† la classe Victoire du premier pok√©mon. Dans ce probl√®me binaire, en augmentant le poids d'une modalit√©, on augmente son influence sur la croissance de l'arbre et on r√©duit en m√™me temps la modalit√© inverse. 


En associant un poids plus important √† la d√©faite, la qualit√© des pr√©dictions des arbres binaires et des for√™ts al√©atoires s'am√©liorent de mani√®re n√©gligeable. La fluctuation de la qualit√© des pr√©dictions par rapport aux poids des classes pour l'arbre de d√©cision peut s'expliquer par la variance importante du mod√®le et ne peut donc pas √™tre prise en compte. M√™me en utilisant l'option *balanced* pour les poids des classes sur sklearn et en augmentant le nombre de plis de la validation, aucune diff√©rence statistique pertinente est observable. L'observation que nous avons fait au niveau du biais des donn√©es n'affecte donc pas le classifieur.

{{< image src="/img/pokemon_balance_difference.png"  position="center" >}}
{{< caption title="Qualit√© du mod√®le de pr√©diction des taux de victoire par rapport aux poids attribu√©s √† chaque classe (sans optimisation d'autres hyper-param√®tres)" >}}

---
## Adaptative Boosting

### Principe

Le boosting est une m√©thode qui consiste √† construire s√©quentiellement une suite de mod√®les simples pour constituer un mod√®le plus puissant. 

Pour un probl√®me de classification binaire d'une variable $y$, l'algorithme Adaboost consid√®re que les individus sont tous initialement uniform√©ment pond√©r√©s. A l'it√©ration $i$, un nouveau mod√®le $M^i$ est construit avec le mod√®le de base sur l'√©chantillon d'entra√Ænement avec le poids courant des individus. Son taux d'erreur $\varepsilon^i$ de classification est alors calcul√© puis le poids $\alpha^i$
ainsi que la pond√©ration des individus $\omega_j$ qui sera ensuite normalis√©e. L'algorithme converge lorsque le nombre de mod√®les est satisfait ou lorsque l'erreur est plus petite qu'un seuil donn√©. 

$$\varepsilon^i = \frac{\sum_{j=1}^n\omega_j\unicode{x1D7D9}(y_j \neq M^i(j))}{\sum_{j=1}^n\omega_j}$$

$$\alpha^i = log\left(\frac{1 - \varepsilon^i}{\varepsilon^i}\right)$$
    
$$\omega_j^{i+1} = \omega_j^{i} \times exp(\alpha^i \times \unicode{x1D7D9}(y_j \neq M^i(j)))$$

La mise √† jour de la pond√©ration des individus attribue un poids plus important aux individus mal classifi√©s, ce qui incite le mod√®le de boosting sur les it√©rations suivantes √† corriger les zones probl√©matiques en terme de classification. Cet avantage est √† double tranchant puisqu'il rend le mod√®le plus sensible aux donn√©es bruit√©es ainsi qu'√† une mauvaise classification. 

En g√©n√©rale, Adaboost fonctionne mieux avec des mod√®les de base simples avec des puissances de pr√©diction faible comme les arbres de d√©cision.

### Application

L'application d'Adaboost sur l'arbre de d√©cision donne un r√©sultat similaire √† un arbre simple. Ce s'explique par la complexit√© de l'arbre optimal initial (de profondeur 5) ainsi que la pr√©sence des r√©sultats inattendus de certains combats (victoire d'un pok√©mon d√©favoris√© √† l'√©gard des statistiques de combats) auxquelles le mod√®le est plus sensible. 

{{< image src="/img/pokemon_pdp_difference.jpg"  position="center" >}}
{{< caption title="Graphique de d√©pendance partielle des variables les plus importantes du mod√®le Adaboost de pr√©diction des combats" >}}

Le graphique de d√©pendance (repr√©sentation qui montre l'influence d'une ou de plusieurs variables marginales sur la pr√©diction. Pour un probl√®me de classification binaire, toute zone de probabilit√© $>0.5$ correspond √† un $True$.) montre une rupture des fronti√®res de d√©cision claire qui se produit au niveau de *diff\_speed* $= 0$. La d√©pendance partielle de la diff√©rence de vitesse va contre l'intuition que la diff√©rence de vitesse influence lin√©airement la probabilit√© de victoire du pok√©mon avantag√©.

La forme inattendue ($1/x$) que prend la d√©pendance partielle des diff√©rence de vitesse peut s'expliquer par la dominance des diff√©rences des taux de victoires dans le mod√®le. L'inclusion de cette variable bruit√©e affaiblit fortement le mod√®le. Sa suppression engendre alors une am√©lioration visible du taux de pr√©diction correcte de $0.909$ √† $0.940$ et une correction de l'√©volution de la d√©pendance partielle.

---
## Conclusion

### √âvaluation des performances

Afin de comparer les performances entre diff√©rentes familles d'algorithmes, la proc√©dure commune suivante a √©t√© suivie:

- Le jeu de donn√©es est divis√© en un √©chantillon d'entra√Ænement et de test ($33\%$ des donn√©es) gr√¢ce √† GridSearchCV.
- L'estimateur de performance choisie est l'accuracy\_score qui calcule la correspondance exacte de la pr√©diction et de la classe r√©elle par la formule:
    $$\texttt{accuracy}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples}-1} \unicode{x1D7D9}(\hat{y}_i = y_i)$$
  Cet indicateur correspond bien √† notre cas d'usage puisqu'il s'agit d'un probl√®me de classification binaire o√π le r√©sultat d'un combat est d√©terministe.
- Le crit√®re de qualit√© est alors calcul√© par validation crois√©e √† cinq coupes afin de r√©duire le biais et optimis√© sur l'espace d'hyper-param√®tre correspondant. 

|      Mod√®les      | Accuracy score |
|:-----------------:|:--------------:|
|        KNN        |      0.92      |
|        SVM        |     0.9273     |
| Arbre de d√©cision |      0.945     |
|  For√™t al√©atoire  |      0.949     |
|  AdaBoost d‚Äôarbre |      0.940     |


M√™me avec une √©valuation pessimiste de la qualit√©, les mod√®les construits peuvent tous r√©pondre ad√©quatement √† notre probl√©matique. 

Afin de minimiser le temps d'entra√Ænement, d'optimiser la qualit√© du mod√®le et de maintenir l'interpr√©tabilit√©, l'arbre de d√©cision correspond au choix optimal pour notre jeu de donn√©es synth√©tiques. On peut alors √©mettre l'hypoth√®se suivante sur la g√©n√©ration des donn√©es : la victoire est g√©n√©r√©e selon deux conditions sur la diff√©rence de vitesse et d'attaque entre les deux pok√©mons puis du bruit al√©atoire introduit pour complexifier la classification.  


### Conclusions et futurs travaux

Ce projet nous a permis d'appliquer et de comprendre les algorithmes de classification vus en cours sur un jeu de donn√©es "r√©elles" et d'explorer d'autres mod√®les comme les SVM ou l'Adaboost. Il nous a aussi fait comprendre l'importance de l'analyse pr√©liminaire et du nettoyage dans la construction d'un mod√®le d'apprentissage automatique. 

Pour aller plus loin, on peut √©tudier d'autres algorithmes comme la r√©gression logistique ou les analyses discriminantes. De plus, on peut identifier et √©tudier les zones probl√©matiques pour chaque classifieur et d√©terminer si certains attributs suivent une distribution particuli√®re dans ces zones. Puis dans un deuxi√®me temps, scinder le jeu de donn√©es en partie probl√©matique et non probl√©matique puis appliquer des mod√®les diff√©rentes √† chaque partie. Enfin, afin d'obtenir un jeu de donn√©es plus repr√©sentatif du jeu Pok√©mon, peut-√™tre que r√©cup√©rer les r√©sultats de combats r√©ellement jou√©s par des joueurs serait pertinent. Des applications comme "Pok√©mon Showdown" le permettent.